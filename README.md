# ğŸ““LLM_Articals
Collection of  some good LLM articals

[internal huggingface blog link](https://github.com/PirateforFreedom/blog)


## ğŸ“–  First collection in LLM-blog
###  ğŸ˜¶ [The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture](https://deeprevision.github.io/posts/001-transformer/).
###  ğŸ˜ [Optimizing LLMs from a Dataset Perspective](https://lightning.ai/pages/community/tutorial/optimizing-llms-from-a-dataset-perspective/).
### ğŸ«¤[Fine-tune Falcon 180B with QLoRA and Flash Attention on Amazon SageMaker](https://www.philschmid.de/sagemaker-falcon-180b-qlora).
### ğŸ˜œ[An international student's perspective on applying for CS/AI/NLP PhD in the US](https://shaoyijia.github.io/blog/2023/apply-grad-school/).
### ğŸ˜‰ [How do domain-specific chatbots work? An Overview of Retrieval Augmented Generation (RAG)](https://scriv.ai/guides/retrieval-augmented-generation-overview/).
###  ğŸ˜†[Understanding AI Agents in the age of LLMs!](https://twitter.com/akshay_pachaar/status/1697950190756585700).
### ğŸ˜…[Generative AI and intellectual property](https://www.ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property).
### ğŸ˜ƒ[Ahead of AI #11: New Foundation Models](https://magazine.sebastianraschka.com/p/ahead-of-ai-11-new-foundation-models).
### ğŸ˜€[Llama 2 learns to code](https://huggingface.co/blog/codellama).
### ğŸ˜[Introduction to Quantization cooked in ğŸ¤— with ğŸ’—ğŸ§‘â€ğŸ³](https://huggingface.co/blog/merve/quantization).
### ğŸ˜‚ [Fine-tune Llama 2 with DPO](https://huggingface.co/blog/dpo-trl)
### ğŸ¤£ [Deep Neural Nets: 33 years ago and 33 years from now](https://karpathy.github.io/2022/03/14/lecun1989/)
## ğŸ“œ Second collection in LLM-lecture
### ğŸ˜ƒ [CS324 lecture notes (Winter 2022)](stanford-cs324.github.io/winter2022/lectures/)


